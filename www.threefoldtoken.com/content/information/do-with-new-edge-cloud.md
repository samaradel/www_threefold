+++

#Don't remove name!
title = "What can I do with the New Edge Cloud"
image = "../img/what-can-i-do.jpg"
author = "Weynand Kujipers"
subtitle = "Some description of use cases of how the ThreeFold Edge Cloud can be used."
weight = 7

+++

## Any Docker Service
0-node runs containers natively - therefore it can run any Docker service.  But it does so a lot more efficient than docker engine, the most used and know container technology platforms.

Improvements
Secure Recipe (docker gets converted to a metadata description)
Dedupe (1/100 of storage required)
Thin Provisioning (so only files required to run will be fetched from the network)
Runs inside a VDC = Seamless network integration over unlimited amount of sites
Attach 0-Disks: can attach fast redundant virtual disks to dockers which maintain state
Integrated in our Cockpit techno (self driving techno)

### IAAS

Infrastructure as a Service workloads run very efficiently on a 0-node.  The 0-node technology enables hardware capabilities to be used in a very efficient way.  Overhead is reduced to a minimum by stripping out unnecessary layers of software that have been invented and implemented over the last decade to patch scaling and performance problems.  We have always looked at the root cause of the issue and by innovating at the core algorithm level solved the issue.   Examples are:

- **Less is more**: Eradicate the host-operating system for a virtualised solution to a minimum and make it boot over the network - no local operating system installed on hardware
- **Look at root causes, do not invent painkillers**: Step away from existing storage solutions that have a need for proprietary acceleration hardware and use standard off the shelf, affordable and efficient components with a 100% software based storage solution that is able to overcome hardware failures without human intervention - creating a very efficient, reliable and performing storage solution that can operate standalone.

The platform is secure by using a network boot mechanism taking out the possibility to change any locally installed OS files making it almost hack resistant.
Infrastructure as a service is traditionally runs in hyperscale datacenters remote from the businesses using it. 0-node technology allows you to install, operate and run IAAS services close to your business locations operated by your local IT team.  It operates on a peer2peer network only transferring bits of data that need to be transported avoiding network congestion and traffic bottlenecks.

### Archive
Data generation is growing exponentially. More data has been generated in the last 2 years than ever before. This data needs to be archived. The 0-node technology creates storage and archiving capabilities by using standard hardware and has known interfaces available to use (S3, FTP, WebDav, CIFS and NFS).  It supports version controlling of the archived data to keep all relevant changes without any limitation while using a small amount of actual storage capacity.  

Data security and reliability are key aspects of any storage system.  The 0-node allows all data to be compressed and encrypted if and when needed. The distributed character of the storage system enables site redundant storage algorithms to be deployed keeping large data volumes from being stored in a single location taking away the risk of data being stolen (physically) and that of a site outage leading to a data outage.  The distributed character of the system is inline with the increasing spread of actual data generation.  We have sensory equipment everywhere these days and the overhead of storing all that information in a few central places is enormous  Data collection and storage happens once - reading data to use it for a particular workload happens many times.

### Data Mining
On traditional server architectures, every application has to set up its own servers that run their own code in isolated silos, making sharing of data hard. The distributed character of the 0-node technology presents compute and storage capacity everywhere.  This enables large data mining workloads to happen close to the source of the data.  Data is stored in a distributed manner and therefore data mining can happen in a distributed manner as well. Distributed compute capacity next to storage capabilities creates the possibility to create data mining operations on local storage (which makes it very fast and efficient) by coding data mining algorithms in programming languages like python, lua, javascript and golang. Data mining follows distributed data storage.

Never run into scalability problems again - the 0-node data store can expand horizontally using thousands of distributed nodes to create large storage volumes.

### Smart Contracts

Smart contracts are applications that run on a decentralised platform, exactly as programmed without any possibility of downtime, censorship, fraud or third party interference . These apps run on a blockchain, an enormously powerful shared global infrastructure that can move value around and represent the ownership of property. Smart contracts enable developers to create markets, store registries of debts (or promises), move funds in accordance with instructions given long in the past (like a will or a futures contract) and many other things without a middleman or counterparty risk.


The 0-node technology natively supports the existing Ethereum network  and will have it's own way of running smart contracts by deploying a  new blockchain technology called rivine.io, presenting a whole new approach on how to run  blockchain.

### Self Learning & AI
Blockchains can be seen as databases. By current database standards, traditional blockchains like Bitcoin are terrible: low throughput, low capacity, high latency, poor query support, and so on. But even with these terrible characteristics blockchains introduce three new and important characteristics:

- Decentralized data and shared data control.  Very simply said this leads to more data and qualitative better data which result in better models. shortening the machine learning time and get AI progressing in a much faster pace.  
- Immutable audit trails improve the trustworthiness of the data & models increasing provenance on training and testing results.
- Native assets and  assets exchanges make  training and testing models intellectual property (IP) assets, which enhancing decentralized data & model exchanges.

Blockchain technology allows more data and with better quality to be presented to machine learning algorithms.  It has been proven (Microsoft researchers Banko and Brill) that more data — not just a bit more data but orders of magnitude more data — while  using same algorithms results in a lot better machine learning.  Meaning that the future of machine learning is not in trying to create more sophisticated algorithms (which will happen) .  So by moving AI learning into a blockchain environment we speed up machine learning and in the end create AI.
